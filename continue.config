............
"models": [
    {
      "title": "Llama 3.1 8B",
      "provider": "ollama",
      "model": "llama3.1:8b"
    },
    {
      "title": "Llama CPP",
      "provider": "llama.cpp",
      "model": "LLAMA-CPP-GPU-ACCEL",
      "apiBase": "http://localhost:8080"
    },
...........
